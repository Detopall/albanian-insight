{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Albanian POS Tagging\n",
    "\n",
    "This notebook will use this [Albanian POS](https://github.com/NeldaKote/Albanian-POS/blob/master/albanian-all-devel-new.conllu) dataset that contains 10,000 sentences with their POS tags. The dataset is in the CoNLL-U format.\n",
    "\n",
    "The dataset will be trained on a `CRF` model from the `sklearn_crfsuite` package to predict the POS tags of the Albanian language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('./models'):\n",
    "\tos.makedirs('./models')\n",
    "\n",
    "if not os.path.exists('./models/pos'):\n",
    "\tos.makedirs('./models/pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved successfully at: ./models/pos/pos_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pyconll\n",
    "from sklearn_crfsuite import CRF\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "def load_conllu_file(file_path):\n",
    "    sentences = []\n",
    "    pos_tags = []\n",
    "    conll = pyconll.load_from_file(file_path)\n",
    "    for sentence in conll:\n",
    "        words = []\n",
    "        tags = []\n",
    "        skip_sentence = False\n",
    "        for token in sentence:\n",
    "            if token.form is None or token.upos is None:\n",
    "                skip_sentence = True\n",
    "                break\n",
    "            words.append(token.form)\n",
    "            tags.append(token.upos)\n",
    "        if not skip_sentence:\n",
    "            sentences.append(words)\n",
    "            pos_tags.append(tags)\n",
    "    return sentences, pos_tags\n",
    "\n",
    "# Load CoNLL-U file and filter out None values\n",
    "sentences, pos_tags = load_conllu_file('./data/albanian-all-devel-new.conllu')\n",
    "\n",
    "# Step 2: Train the CRF Model\n",
    "crf = CRF(algorithm='lbfgs', max_iterations=100)\n",
    "crf.fit(sentences, pos_tags)\n",
    "\n",
    "# Step 3: Save the Model\n",
    "model_path = \"./models/pos/\"\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "model_file = os.path.join(model_path, \"pos_model.pkl\")\n",
    "joblib.dump(crf, model_file)\n",
    "\n",
    "print(\"Model trained and saved successfully at:\", model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ky PRON\n",
      "është VERB\n",
      "një NUM\n",
      "shembull NOUN\n",
      "i DET\n",
      "një NUM\n",
      "teksti NOUN\n",
      "të DET\n",
      "shkruar ADJ\n",
      "në ADP\n",
      "gjuhën NOUN\n",
      "shqipe. ADJ\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = joblib.load(model_file)\n",
    "\n",
    "# Test the model\n",
    "text = \"Ky është një shembull i një teksti të shkruar në gjuhën shqipe.\" # This is an example of a text written in the Albanian language.\n",
    "\n",
    "tokens = text.split()\n",
    "pos_tags = model.predict([tokens])[0]\n",
    "\n",
    "for token, pos_tag in zip(tokens, pos_tags):\n",
    "\tprint(token, pos_tag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "albanian-NLP-fTaZVMI_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
